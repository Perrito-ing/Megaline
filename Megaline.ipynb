{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# \u00a1Hola Sebastian! \ud83d\ude0a\n\nMi nombre es **Alejandro Castellanos** y hoy tengo el placer de ser el revisor de tu proyecto.\n\nVoy a revisar todo tu c\u00f3digo con detalle, buscando tanto los puntos fuertes como aquellos en los que podr\u00edas mejorar. Te dejar\u00e9 comentarios a lo largo del notebook, destacando lo que has hecho bien y sugiriendo ajustes donde sea necesario. Si encuentro alg\u00fan error, no te preocupes, te lo har\u00e9 saber de forma clara y te dar\u00e9 informaci\u00f3n \u00fatil para que puedas corregirlo en la pr\u00f3xima iteraci\u00f3n. Si en alg\u00fan punto tienes comentarios, si\u00e9ntete libre de dejarlos tambi\u00e9n.\n\n\nEncontrar\u00e1s mis comentarios espec\u00edficos dentro de cajas verdes, amarillas o rojas, es muy importante que no muevas, modifiques o borres mis comentarios, con el fin de tener un seguimiento adecuado de tu proceso:\n\n\n<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\u201ctocSkip\u201d></a>\nSi todo est\u00e1 perfecto.\n</div>\n\n<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor</b> <a class=\u201ctocSkip\u201d></a>\nSi tu c\u00f3digo est\u00e1 bien pero se puede mejorar o hay alg\u00fan detalle que le hace falta.\n</div>\n\n<div class=\"alert alert-block alert-danger\">\n<b>Comentario del revisor</b> <a class=\u201ctocSkip\u201d></a>\nSi de pronto hace falta algo o existe alg\u00fan problema con tu c\u00f3digo o conclusiones.\n</div>\n\nPuedes responderme de esta forma:\n<div class=\"alert alert-block alert-info\">\n<b>Respuesta del estudiante</b> <a class=\u201ctocSkip\u201d></a>\n</div>\n\nA continuaci\u00f3n te dejar\u00e9 un comentario general con mi valoraci\u00f3n del proyecto. **\u00a1Mi objetivo es que sigas aprendiendo y mejorando con cada paso!**"}, {"cell_type": "markdown", "metadata": {}, "source": "----"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-warning\">\n<b>Comentario General del revisor (1ra Iteraci\u00f3n)</b> <a class=\u201ctocSkip\u201d></a>\n\nSebastian has hecho un buen trabajo. En este proyecto pusiste en pr\u00e1ctica habilidades muy importantes como dividir correctamente los datos, entrenar modelos de clasificaci\u00f3n, probar diferentes algoritmos y ajustar hiperpar\u00e1metros para mejorar el resultado.\n    \nNo obstante, para cumplir con el objetivo del proyecto debes usar correctamente y de forma estrategica los subconjuntos de entrenamiento, validaci\u00f3n y prueba para la implementaci\u00f3n de los modelos.  El conjunto de **entrenamiento** permite que el modelo aprenda patrones; por otro lado, el de **validaci\u00f3n** se utiliza en la optimizaci\u00f3n de hiperpar\u00e1metros, con el fin de encontrar la configuraci\u00f3n con la que cada modelo tiene mejor rendimiento, adem\u00e1s de que sirve para detectar sobreajuste; finalmente el subconjunto de **prueba** eval\u00faa su capacidad de generalizaci\u00f3n en datos completamente nuevos y permite hacer una comparaci\u00f3n final en el desempe\u00f1o de varios modelos. Esta separaci\u00f3n garantiza una evaluaci\u00f3n objetiva, evita el sobreajuste y asegura que el modelo sea confiable. Ac\u00e1 te comparto una explicaci\u00f3n m\u00e1s detallada de c\u00f3mo usar los [sets de entrenamiento, validaci\u00f3n y prueba](https://codificandobits.com/blog/sets-entrenamiento-validacion-y-prueba/)\n    \n\u00a1No te preocupes! Cada ajuste que haces es una oportunidad para aprender y mejorar. Vas por buen camino, y estoy seguro de que en la siguiente versi\u00f3n har\u00e1s un gran trabajo y lograr\u00e1s completar el proyecto con \u00e9xito. \u00a1Sigue adelante! \n\nEstar\u00e9 atento a tu pr\u00f3xima iteraci\u00f3n \ud83d\udc40\n\n\n    \n<div class=\"alert alert-block alert-info\">\n<b>Respuesta del estudiante (1ra Iteraci\u00f3n)</b> <a class=\u201ctocSkip\u201d></a>\n\nHola Alejandro, primero que nada gracias por tomarte el tiempo de revisar mi trabajo. Y gracias por el Link, me aclaro varias cosas. Espero que con estos cambios se hayan subsanado todas las observaciones. \ud83d\ude42\n    \n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor (2da Iteraci\u00f3n)</b> <a class=\u201ctocSkip\u201d></a>\n\n\u00a1Sebatian excelente trabajo con los ajustes! Tu proyecto ahora cumple con todos los objetivos propuestos. Me alegra saber que la informaci\u00f3n que te compart\u00ed te fue \u00fatil, esto ser\u00e1 clave para los siguientes proyectos. \u00a1\u00c9xito en tu pr\u00f3ximo sprint! \ud83d\ude80\n\n*Estado del Proyecto:* **Aprobado**\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "-----"}, {"cell_type": "markdown", "metadata": {}, "source": "# Proyecto Sprint 9"}, {"cell_type": "markdown", "metadata": {}, "source": "## Descripci\u00f3n del proyecto"}, {"cell_type": "markdown", "metadata": {}, "source": "La compa\u00f1\u00eda m\u00f3vil Megaline no est\u00e1 satisfecha al ver que muchos de sus clientes utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra.\n\nDesarrolla un modelo con la mayor exactitud posible. En este proyecto, el umbral de exactitud es 0.75. "}, {"cell_type": "markdown", "metadata": {}, "source": "## Manipulaci\u00f3n de datos"}, {"cell_type": "code", "execution_count": 1, "metadata": {"trusted": true}, "outputs": [], "source": "#Cargamos librerias\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression"}, {"cell_type": "code", "execution_count": 2, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "      calls  minutes  messages   mb_used  is_ultra\n0      40.0   311.90      83.0  19915.42         0\n1      85.0   516.75      56.0  22696.96         0\n2      77.0   467.66      86.0  21060.45         0\n3     106.0   745.53      81.0   8437.39         1\n4      66.0   418.74       1.0  14502.75         0\n...     ...      ...       ...       ...       ...\n3209  122.0   910.98      20.0  35124.90         1\n3210   25.0   190.36       0.0   3275.61         0\n3211   97.0   634.44      70.0  13974.06         0\n3212   64.0   462.32      90.0  31239.78         0\n3213   80.0   566.09       6.0  29480.52         1\n\n[3214 rows x 5 columns]\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3214 entries, 0 to 3213\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   calls     3214 non-null   float64\n 1   minutes   3214 non-null   float64\n 2   messages  3214 non-null   float64\n 3   mb_used   3214 non-null   float64\n 4   is_ultra  3214 non-null   int64  \ndtypes: float64(4), int64(1)\nmemory usage: 125.7 KB\nNone\n"}], "source": "#Verificamos el DataFrame para ver su contenido\ndf = pd.read_csv(\"users_behavior.csv\", sep=\",\")\n\nprint(df)\nprint()\nprint(df.info())"}, {"cell_type": "markdown", "metadata": {}, "source": "Viendo los datos, podemos determinar lo siguiente:\n\n1. Las columnas \"calls\", \"minutes\", \"messages\" y \"mb_used\" son nuestras caracteristicas.\n2. La clumna \"is_ultra\" es nuestro objetivo.\n3. La columna objetivo al contener valores booleanos nos indica que estamos ante una tarea de clasificacion."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor (1ra Iteraci\u00f3n)</b> <a class=\u201ctocSkip\u201d></a>\n\nMuy buen trabajo importando las librer\u00edas y los datos del proyecto. Adicionalmente usaste correctamente las funciones `info` y `head`, esto te permite hacer una primera revisi\u00f3n de los datos, su estructura y contenido. \n\n<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor (1ra Iteraci\u00f3n)</b> <a class=\u201ctocSkip\u201d></a>\n    \nUna buena pr\u00e1ctica al momento de hacer la revisi\u00f3n inicial de los datos es incluir tu interpretaci\u00f3n de la informaci\u00f3n obtenida, con el fin de tener claridad sobre la estrategia que se va a implementar al momento de trabajar con el dataset.\n\n<div class=\"alert alert-block alert-info\">\n<b>Respuesta del estudiante (1ra Iteraci\u00f3n)</b> <a class=\u201ctocSkip\u201d></a>\n    \nTienes razon, coloque un peque\u00f1o comentario sobre los datos.\n    \n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "## Comparacion de Modelos"}, {"cell_type": "code", "execution_count": 3, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Datos fuente(total de datos): 3214\n\nDatos de entrenamiento:  1928\n\nDatos de validacion:  643\n\nDatos de prueba:  643\n"}], "source": "#Imprimimos el largo del DataFrame como referencia\nprint(\"Datos fuente(total de datos):\", len(df))\nprint()\n\n\n#Separamos los datos en tres conjuntos, uno para entrenar el modelo, otro para validarlo y el ultimo para probarlo. con una proporcion de 3:1:1\ndf_train_and_test, df_valid = train_test_split(df, test_size=0.20, random_state=1)\n\ndf_train, df_test = train_test_split(df_train_and_test, test_size=0.25, random_state=1)\n\n#Entrenamiento 60%\nfeatures_train = df_train.drop([\"is_ultra\"], axis=True)\ntarget_train = df_train[\"is_ultra\"]\nprint(\"Datos de entrenamiento: \", len(df_train))\n\n#Validacion 20%\nfeatures_valid = df_valid.drop([\"is_ultra\"], axis=True)\ntarget_valid = df_valid[\"is_ultra\"]\nprint()\nprint(\"Datos de validacion: \", len(df_valid))\n\n#Prueba 20%\nfeatures_test = df_test.drop([\"is_ultra\"], axis=True)\ntarget_test = df_test[\"is_ultra\"]\nprint()\nprint(\"Datos de prueba: \", len(df_test))"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-info\">\n<b>Respuesta del estudiante (1ra Iteraci\u00f3n)</b> <a class=\u201ctocSkip\u201d></a>\n\nAhora si, dividi el DataFrame en tres conjuntos. uno para entrenamiento, otro para validacion y el ultimo para prueba.\n    \n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Comentario del revisor (1ra Iteraci\u00f3n)</b> <a class=\u201ctocSkip\u201d></a>\n\nTen en cuenta que para este caso de estudio se pide dividir el dataset en 3 subconjuntos: **Entrenamiento**, **Validaci\u00f3n** y **Prueba**\n    \nDividir un dataset en entrenamiento, validaci\u00f3n y prueba permite desarrollar, ajustar y evaluar un modelo de forma justa y efectiva.\n\n- El conjunto de entrenamiento se usa para ense\u00f1ar al modelo a reconocer patrones.\n\n- El de validaci\u00f3n se emplea para ajustar hiperpar\u00e1metros y prevenir sobreajuste.\n\n- El de prueba sirve para medir el rendimiento final del modelo con datos nunca vistos.\n    \n<div class=\"alert alert-block alert-info\">\n<b>Respuesta del estudiante (1ra Iteraci\u00f3n)</b> <a class=\u201ctocSkip\u201d></a>\n\nEn esta ocasion dividi cada modelo en dos bloques:\n- Uno para entrenar y determinar el ajuste (que es como estaba el proyecto en la primera iteracion).\n- Y el otro, a modo de correcion de las observaciones que me indicaste. En donde sabiendo cual es el hiperparametro mas optimo se procede a entrenar, validar y probar el modelo ya ajustado.\n    \n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor (2da Iteraci\u00f3n)</b> <a class=\u201ctocSkip\u201d></a>\n\nHiciste una correcta segmentaci\u00f3n del dataset en los subconjuntos de entrenamiento, validaci\u00f3n y prueba, lo cual permite evaluar el rendimiento real del modelo y prevenir el sobreajuste. Esta separaci\u00f3n garantiza que el modelo generalice bien y no solo funcione con los datos que utiliz\u00f3 para aprender.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "### Arbol de decision"}, {"cell_type": "markdown", "metadata": {}, "source": "#### Entrenamiento y validacion para determinar el ajuste"}, {"cell_type": "code", "execution_count": 4, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Con una profundidad maxima de 1 obtenemos una exactitud de: 0.717\nCon una profundidad maxima de 2 obtenemos una exactitud de: 0.7621\nCon una profundidad maxima de 3 obtenemos una exactitud de: 0.7745\nCon una profundidad maxima de 4 obtenemos una exactitud de: 0.776\nCon una profundidad maxima de 5 obtenemos una exactitud de: 0.7792\nCon una profundidad maxima de 6 obtenemos una exactitud de: 0.7792\nCon una profundidad maxima de 7 obtenemos una exactitud de: 0.79\nCon una profundidad maxima de 8 obtenemos una exactitud de: 0.7854\nCon una profundidad maxima de 9 obtenemos una exactitud de: 0.7854\nCon una profundidad maxima de 10 obtenemos una exactitud de: 0.7869\n"}], "source": "#empezaremos con el arbol de decision, iterando sobre el hiperparametro de profundidad maxima para ajustar la exactitud.\nfor depth in range(1, 11):\n    model = DecisionTreeClassifier(random_state=3, max_depth=depth)\n    model.fit(features_train, target_train)\n    predictions_valid = model.predict(features_valid)\n    accuracy = round(accuracy_score(target_valid, predictions_valid), 4)\n    print(\"Con una profundidad maxima de {} obtenemos una exactitud de: {}\".format(depth, accuracy))"}, {"cell_type": "markdown", "metadata": {}, "source": "El mejor modelo fue el que tuvo una profundidad maxima de 7"}, {"cell_type": "markdown", "metadata": {}, "source": "#### Prueba del modelo"}, {"cell_type": "code", "execution_count": 5, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Con una profundidad maxima de 7 obtenemos una exactitud de: 0.7869 con los datos de validacion\n\nObtuvimos una exactitud de: 0.7869 con los datos de prueba\n"}], "source": "#conociendo el ajuste del hiperparametro volvemos a entrenar el modelo desde el principio de forma ordenada\n\n#creacion de modelo con una profundidad maxima de 7, tambien se cambia el valor de random_state\nmodel_decision_tree = DecisionTreeClassifier(random_state=4, max_depth=7)\n\n#entrenamiento\nmodel_decision_tree.fit(features_train, target_train)\n\n#validacion\npredictions_valid = model_decision_tree.predict(features_valid)\naccuracy = round(accuracy_score(target_valid, predictions_valid), 4)\nprint(\"Con una profundidad maxima de 7 obtenemos una exactitud de: {} con los datos de validacion\".format(accuracy))\nprint()\n\n#prueba con conjunto de datos desconocidos\npredictions_test = model_decision_tree.predict(features_test)\naccuracy_test = round(accuracy_score(target_test, predictions_test), 4)\nprint(\"Obtuvimos una exactitud de: {} con los datos de prueba\".format(accuracy_test))\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "Tanto en la validacion como en la prueba obtuvimos una exactitud similar. lo cual indicaria que el modelo es bastante preciso aun con datos desconocidos para este."}, {"cell_type": "markdown", "metadata": {}, "source": "### Bosque aleatorio"}, {"cell_type": "markdown", "metadata": {}, "source": "#### Entrenamiento y validacion para determinar el ajuste"}, {"cell_type": "code", "execution_count": 6, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "La exactitud del modelo con 1 arbolitos es de: 0.7247\nLa exactitud del modelo con 2 arbolitos es de: 0.7574\nLa exactitud del modelo con 3 arbolitos es de: 0.776\nLa exactitud del modelo con 4 arbolitos es de: 0.7823\nLa exactitud del modelo con 5 arbolitos es de: 0.7745\nLa exactitud del modelo con 6 arbolitos es de: 0.7698\nLa exactitud del modelo con 7 arbolitos es de: 0.7698\nLa exactitud del modelo con 8 arbolitos es de: 0.7807\nLa exactitud del modelo con 9 arbolitos es de: 0.7667\nLa exactitud del modelo con 10 arbolitos es de: 0.7838\n"}], "source": "#seguimos con el bosque aleatorio, iterando sobre el hiperparametro de numero de estimadores para llegar al mas exacto.\nfor est in range(1, 11):\n    model = RandomForestClassifier(random_state=5, n_estimators=est)\n    model.fit(features_train, target_train)\n    score = model.score(features_valid, target_valid)\n    print(\"La exactitud del modelo con {} arbolitos es de: {}\".format(est, round(score,4)))"}, {"cell_type": "markdown", "metadata": {}, "source": "El mejor modelo fue el que tuvo un numero de estimadores o arboles de 10"}, {"cell_type": "markdown", "metadata": {}, "source": "#### Prueba del modelo"}, {"cell_type": "code", "execution_count": 7, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Con un numero de 10 arbolitos obtuvimos una exactitud de: 0.7885 con los datos de validacion\n\nObtuvimos una exactitud de: 0.7932 con los datos de prueba\n"}], "source": "#conociendo el ajuste del hiperparametro volvemos a entrenar el modelo desde el principio de forma ordenada\n\n#creacion de modelo con un numero de 10 estimadores, tambien se cambia el valor de random_state\nmodel_random_forest = RandomForestClassifier(random_state=6, n_estimators=10)\n\n#entrenamiento\nmodel_random_forest.fit(features_train, target_train)\n\n#validacion\npredictions_valid = model_random_forest.predict(features_valid)\nscore_valid = model_random_forest.score(features_valid, target_valid)\nprint(\"Con un numero de 10 arbolitos obtuvimos una exactitud de: {} con los datos de validacion\".format(round(score_valid,4)))\nprint()\n\n#prueba con conjunto de datos desconocidos\npredictions_test = model_random_forest.predict(features_test)\nscore_test = model_random_forest.score(features_test, target_test)\nprint(\"Obtuvimos una exactitud de: {} con los datos de prueba\".format(round(score_test,4)))\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "Tenemos una buena precison y la exactitud vario un poco entre los valores de validacion y de prueba, pero esto es algo esperable."}, {"cell_type": "markdown", "metadata": {}, "source": "### Regresion logistica"}, {"cell_type": "code", "execution_count": 8, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "La exactitud del modelo en el conjunto de entrenamiento fue de: 0.751\n\nLa exactitud del modelo en el conjunto de validaci\u00f3nfue de: 0.7138\n\nLa exactitud del modelo en el conjunto de prueba fue de: 0.7496\n"}], "source": "#En el caso de regresion logistica al no haber un hiperparametro que ajustar simplemente vamos a entrenar el modelo\n\n#creacion de modelo\nmodel_log_reg = LogisticRegression(random_state=7, solver=\"liblinear\")\n\n#entrenamiento\nmodel_log_reg.fit(features_train, target_train)\n\n#validacion (datos de entrenamiento y validacion)\nscore_train_log_reg = model_log_reg.score(features_train, target_train)\nscore_valid_log_reg = model_log_reg.score(features_valid, target_valid)\nprint(\"La exactitud del modelo en el conjunto de entrenamiento fue de:\", round(score_train_log_reg, 4))\nprint()\nprint(\"La exactitud del modelo en el conjunto de validaci\u00f3nfue de:\", round(score_valid_log_reg, 4))\nprint()\n\n\n#prueba con conjunto de datos desconocidos\nscore_test_log_reg = model_log_reg.score(features_test, target_test)\nprint(\"La exactitud del modelo en el conjunto de prueba fue de:\", round(score_test_log_reg, 4))"}, {"cell_type": "markdown", "metadata": {}, "source": "Desafortunadamente el modelo no cumplio con nuestro requisito de exactitud de 75%"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor (1ra Iteraci\u00f3n)</b> <a class=\u201ctocSkip\u201d></a>\n\nImplementaste correctamente los modelos de clasifiaci\u00f3n, incluyendo la etapa de optimizaci\u00f3n de hiperp\u00e1rametros. No obstante, la implementaci\u00f3n de los modelos debe hacerse usando los 3 subconjuntos que te mencion\u00e9 m\u00e1s arriba: **Entrenamiento**, **Validaci\u00f3n** y **Prueba**\n    \n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor (2da Iteraci\u00f3n)</b> <a class=\u201ctocSkip\u201d></a>\n\nExcelente Sebastian, ahora el flujo de implementaci\u00f3n de los modelos es m\u00e1s robusto, lo cual te puede permitir llegar a tener mejores rendimientos\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "### Conclusion"}, {"cell_type": "markdown", "metadata": {}, "source": "Los modelos Arbol de Decision y Bosque Aleatorio tuvieron un desempe\u00f1o my similar al ajustar sus hipercampos, ambos alcanzando una exactitud de aproximadamente el 79%. Lo cual cumple con nuestro requisito minimo de exactitud que es del 75%.\n\nEn cuanto al modelo de Regresion Logistica su desempe\u00f1o no fue el mejor. Sin embargo, podriamos decir que en cuanto a tareas de categorizacion este modelo no es el mejor. Mas bien esta pensado para tareas de regresion."}, {"cell_type": "markdown", "metadata": {}, "source": "## Conclusion General"}, {"cell_type": "markdown", "metadata": {}, "source": "Ya habiendo entrenado los diferentes modelos vimos que el Arbol de decision y el Bosque Aleatorio alcanzaron una exactitud identica. \n\nAhora bien, cada modelo tiene sus caracteristicas que los hacen mas o menos adecuados dependiendo de la tarea y los recursos con los que se cuentan, siendo sus caracteristicas las siguientes:\n\n* Arbol de decision: Exactitud baja / Velocicad alta\n\n* Bosque aleatorio: Exactitud alta / Velocidad baja\n\nEntonces, si la exactitud fue la misma para ambos modelos; tomaremos logicamente el modelo mas veloz."}, {"cell_type": "markdown", "metadata": {}, "source": "### Conclusion final"}, {"cell_type": "markdown", "metadata": {}, "source": "Para la tarea de clasificacion de usuarios segun su plan, debemos utilizar el modelo de Arbol de Decision y ajustar su profundidad maxima a 7."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor (2da Iteraci\u00f3n)</b> <a class=\u201ctocSkip\u201d></a>\n\nHas logrado comparar correctamente los modelos en funci\u00f3n de su exactitud y velocidad, y justificas de forma l\u00f3gica la elecci\u00f3n final del \u00c1rbol de Decisi\u00f3n como el modelo m\u00e1s adecuado para la tarea espec\u00edfica. Adem\u00e1s, defines claramente el par\u00e1metro clave a ajustar, lo que refuerza la aplicabilidad directa de tu an\u00e1lisis.\n\n</div>"}], "metadata": {"ExecuteTimeLog": [{"duration": 2540, "start_time": "2025-04-29T16:40:53.622Z"}, {"duration": 14, "start_time": "2025-04-29T16:40:56.164Z"}, {"duration": 19, "start_time": "2025-04-29T17:54:27.171Z"}, {"duration": 7, "start_time": "2025-04-29T18:02:08.484Z"}, {"duration": 799, "start_time": "2025-04-30T17:25:45.168Z"}, {"duration": 24, "start_time": "2025-04-30T17:25:46.627Z"}, {"duration": 9, "start_time": "2025-04-30T17:25:50.002Z"}, {"duration": 249, "start_time": "2025-04-30T18:00:43.563Z"}, {"duration": 9, "start_time": "2025-04-30T18:02:23.436Z"}, {"duration": 17, "start_time": "2025-04-30T18:02:25.123Z"}, {"duration": 7, "start_time": "2025-04-30T18:02:27.660Z"}, {"duration": 7, "start_time": "2025-04-30T18:02:29.424Z"}, {"duration": 27, "start_time": "2025-04-30T18:02:34.598Z"}, {"duration": 237, "start_time": "2025-04-30T18:02:36.050Z"}, {"duration": 16, "start_time": "2025-04-30T18:02:37.475Z"}, {"duration": 241, "start_time": "2025-04-30T18:36:45.604Z"}, {"duration": 62, "start_time": "2025-04-30T18:37:56.411Z"}, {"duration": 7, "start_time": "2025-04-30T18:45:52.801Z"}, {"duration": 64, "start_time": "2025-04-30T18:46:14.249Z"}, {"duration": 62, "start_time": "2025-04-30T18:49:10.931Z"}, {"duration": 237, "start_time": "2025-04-30T18:49:18.291Z"}, {"duration": 237, "start_time": "2025-04-30T18:49:29.314Z"}, {"duration": 14, "start_time": "2025-04-30T18:51:38.644Z"}, {"duration": 4, "start_time": "2025-04-30T18:55:06.866Z"}, {"duration": 4, "start_time": "2025-04-30T18:55:31.950Z"}, {"duration": 6, "start_time": "2025-04-30T18:56:18.213Z"}, {"duration": 63, "start_time": "2025-04-30T18:56:26.081Z"}, {"duration": 60, "start_time": "2025-04-30T18:56:32.381Z"}, {"duration": 4, "start_time": "2025-04-30T18:57:37.324Z"}, {"duration": 236, "start_time": "2025-04-30T18:57:47.293Z"}, {"duration": 61, "start_time": "2025-04-30T18:57:58.982Z"}, {"duration": 241, "start_time": "2025-04-30T18:58:02.964Z"}, {"duration": 19, "start_time": "2025-04-30T18:58:37.489Z"}, {"duration": 238, "start_time": "2025-04-30T19:04:53.094Z"}, {"duration": 237, "start_time": "2025-04-30T19:06:13.354Z"}, {"duration": 77, "start_time": "2025-04-30T19:06:21.464Z"}, {"duration": 775, "start_time": "2025-04-30T19:32:15.314Z"}, {"duration": 19, "start_time": "2025-04-30T19:32:16.092Z"}, {"duration": 5, "start_time": "2025-04-30T19:32:16.113Z"}, {"duration": 78, "start_time": "2025-04-30T19:32:16.120Z"}, {"duration": 258, "start_time": "2025-04-30T19:32:16.200Z"}, {"duration": 18, "start_time": "2025-04-30T19:32:16.459Z"}, {"duration": 823, "start_time": "2025-05-01T17:23:46.278Z"}, {"duration": 28, "start_time": "2025-05-01T17:23:47.695Z"}, {"duration": 219, "start_time": "2025-05-01T17:23:51.821Z"}, {"duration": 6, "start_time": "2025-05-01T18:24:34.502Z"}, {"duration": 9, "start_time": "2025-05-01T18:24:45.814Z"}, {"duration": 11, "start_time": "2025-05-01T18:25:18.266Z"}, {"duration": 4, "start_time": "2025-05-01T18:28:25.083Z"}, {"duration": 9, "start_time": "2025-05-01T18:28:29.763Z"}, {"duration": 60, "start_time": "2025-05-01T18:45:11.333Z"}, {"duration": 57, "start_time": "2025-05-01T18:46:06.853Z"}, {"duration": 132, "start_time": "2025-05-01T18:46:12.671Z"}, {"duration": 20, "start_time": "2025-05-01T18:53:29.992Z"}, {"duration": 18, "start_time": "2025-05-01T18:54:20.500Z"}, {"duration": 780, "start_time": "2025-05-02T16:49:21.617Z"}, {"duration": 27, "start_time": "2025-05-02T16:49:22.456Z"}, {"duration": 22, "start_time": "2025-05-02T16:49:24.258Z"}, {"duration": 55, "start_time": "2025-05-02T16:49:28.452Z"}, {"duration": 56, "start_time": "2025-05-02T16:49:41.246Z"}, {"duration": 55, "start_time": "2025-05-02T16:49:47.843Z"}, {"duration": 55, "start_time": "2025-05-02T16:49:53.789Z"}, {"duration": 12, "start_time": "2025-05-02T16:51:34.665Z"}, {"duration": 15, "start_time": "2025-05-02T16:56:43.604Z"}, {"duration": 13, "start_time": "2025-05-02T16:57:26.047Z"}, {"duration": 57, "start_time": "2025-05-02T16:59:49.391Z"}, {"duration": 12, "start_time": "2025-05-02T16:59:52.340Z"}, {"duration": 13, "start_time": "2025-05-02T16:59:57.680Z"}, {"duration": 12, "start_time": "2025-05-02T17:02:38.349Z"}, {"duration": 199, "start_time": "2025-05-02T17:04:58.613Z"}, {"duration": 196, "start_time": "2025-05-02T17:05:15.209Z"}, {"duration": 196, "start_time": "2025-05-02T17:07:19.440Z"}, {"duration": 195, "start_time": "2025-05-02T17:07:48.903Z"}, {"duration": 461, "start_time": "2025-05-02T17:08:04.779Z"}, {"duration": 694, "start_time": "2025-05-02T17:08:29.417Z"}, {"duration": 704, "start_time": "2025-05-02T17:09:26.478Z"}, {"duration": 695, "start_time": "2025-05-02T17:09:55.626Z"}, {"duration": 200, "start_time": "2025-05-02T17:10:06.011Z"}, {"duration": 12, "start_time": "2025-05-02T17:15:21.727Z"}, {"duration": 44, "start_time": "2025-05-02T17:21:50.338Z"}, {"duration": 46, "start_time": "2025-05-02T17:35:34.363Z"}, {"duration": 230, "start_time": "2025-05-02T17:43:09.065Z"}, {"duration": 15, "start_time": "2025-05-02T17:43:53.236Z"}, {"duration": 14, "start_time": "2025-05-02T17:44:02.758Z"}, {"duration": 12, "start_time": "2025-05-02T17:52:52.916Z"}, {"duration": 806, "start_time": "2025-05-02T17:55:56.100Z"}, {"duration": 18, "start_time": "2025-05-02T17:55:56.908Z"}, {"duration": 18, "start_time": "2025-05-02T17:55:56.927Z"}, {"duration": 72, "start_time": "2025-05-02T17:55:56.946Z"}, {"duration": 12, "start_time": "2025-05-02T17:55:57.020Z"}, {"duration": 224, "start_time": "2025-05-02T17:55:57.033Z"}, {"duration": 53, "start_time": "2025-05-02T17:55:57.259Z"}, {"duration": 13, "start_time": "2025-05-02T17:55:57.314Z"}, {"duration": 8, "start_time": "2025-05-02T18:12:05.987Z"}, {"duration": 8, "start_time": "2025-05-02T18:14:17.217Z"}, {"duration": 805, "start_time": "2025-05-02T18:15:45.881Z"}, {"duration": 18, "start_time": "2025-05-02T18:15:46.688Z"}, {"duration": 9, "start_time": "2025-05-02T18:15:46.708Z"}, {"duration": 79, "start_time": "2025-05-02T18:15:46.718Z"}, {"duration": 14, "start_time": "2025-05-02T18:15:46.799Z"}, {"duration": 210, "start_time": "2025-05-02T18:15:46.814Z"}, {"duration": 53, "start_time": "2025-05-02T18:15:47.026Z"}, {"duration": 13, "start_time": "2025-05-02T18:15:47.081Z"}, {"duration": 788, "start_time": "2025-05-02T18:20:10.200Z"}, {"duration": 20, "start_time": "2025-05-02T18:20:10.990Z"}, {"duration": 9, "start_time": "2025-05-02T18:20:11.012Z"}, {"duration": 64, "start_time": "2025-05-02T18:20:11.022Z"}, {"duration": 12, "start_time": "2025-05-02T18:20:11.088Z"}, {"duration": 221, "start_time": "2025-05-02T18:20:11.102Z"}, {"duration": 55, "start_time": "2025-05-02T18:20:11.325Z"}, {"duration": 14, "start_time": "2025-05-02T18:20:11.382Z"}, {"duration": 746, "start_time": "2025-05-02T18:25:43.659Z"}, {"duration": 17, "start_time": "2025-05-02T18:25:44.407Z"}, {"duration": 8, "start_time": "2025-05-02T18:25:44.426Z"}, {"duration": 69, "start_time": "2025-05-02T18:25:44.436Z"}, {"duration": 12, "start_time": "2025-05-02T18:25:44.508Z"}, {"duration": 218, "start_time": "2025-05-02T18:25:44.521Z"}, {"duration": 57, "start_time": "2025-05-02T18:25:44.741Z"}, {"duration": 13, "start_time": "2025-05-02T18:25:44.800Z"}], "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 2}